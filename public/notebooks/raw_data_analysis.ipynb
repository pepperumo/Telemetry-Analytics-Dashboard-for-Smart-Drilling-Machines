{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c476980",
   "metadata": {},
   "source": [
    "# Telemetry Drilling Sessions – Minimal Exploratory Notebook (Domain-Aware)\n",
    "\n",
    "This notebook analyzes raw telemetry captured every 30 seconds from retrofitted Pods on drilling machines (July 2025). It performs ingestion, schema enforcement, timestamp normalization, feature engineering (distance, speed, energy proxy), operational state classification, session segmentation, BLE tagging analysis, descriptive statistics, outlier detection, correlation matrix, and CSV export.\n",
    "\n",
    "Allowed stack only: pandas, numpy, plotly.\n",
    "\n",
    "Domain Semantics Incorporated:\n",
    "- Sampling interval: 30 s (expected regular cadence, gaps imply missing telemetry)\n",
    "- Current thresholds (approx.):\n",
    "  * ~0 A       → OFF / unplugged\n",
    "  * ~0.9 A     → STANDBY (plugged, switch off)\n",
    "  * ~3.9 A     → SPIN (motor on, no load)\n",
    "  * more than 5 A       → DRILLING (under load)\n",
    "- A \"session\" is a contiguous run of samples for a device with no time gap > 1.5 * sampling interval.\n",
    "- BLE tag presence (ble_id) indicates session used a tagged consumable if any non-empty value appears.\n",
    "- Sequence gaps (seq) expose missing packets.\n",
    "\n",
    "Advanced analytics (ML clustering, anomaly detection, profiling, folium maps, model artifacts, parquet) were intentionally removed to keep the environment lightweight. See final section for optional future extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910672f2",
   "metadata": {},
   "source": [
    "### Imports & Configuration \n",
    "Sets up deterministic environment and domain parameters:\n",
    "- Minimal stack imports (pandas, numpy, plotly) for portability.\n",
    "- Absolute project root and data directory to avoid relative path pitfalls inside `public/notebooks`.\n",
    "- Sampling cadence (30 s) and session gap (45 s) define temporal segmentation logic.\n",
    "- Current thresholds map raw amperage to machine operational states (OFF/STANDBY/SPIN/DRILL).\n",
    "- Configuration dict centralizes parameters; file existence check guards early against path errors.\n",
    "Outcome: Printed configuration plus `RAW_FILE exists: True` if the CSV is accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "19bb2b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  raw_file: C:\\Users\\peppe\\Documents\\GitHub\\Telemetry-Analytics-Dashboard-for-Smart-Drilling-Machines\\public\\data\\raw_drilling_sessions.csv\n",
      "  sampling_seconds: 30\n",
      "  session_gap_seconds: 45\n",
      "  current_thresholds: {'off_max': 0.2, 'standby_max': 1.8, 'spin_max': 5.0}\n",
      "  export_csv: drilling_sessions_enriched.csv\n",
      "RAW_FILE exists: True\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Imports & Configuration (Minimal Domain-Aware Version)\n",
    "from __future__ import annotations\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Absolute project root (explicit to avoid nesting mistakes)\n",
    "PROJECT_ROOT = Path(r\"C:/Users/peppe/Documents/GitHub/Telemetry-Analytics-Dashboard-for-Smart-Drilling-Machines\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / 'public' / 'data'\n",
    "PROCESSED_DIR = DATA_DIR\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Raw file absolute path (as you specified)\n",
    "RAW_FILE = DATA_DIR / 'raw_drilling_sessions.csv'\n",
    "\n",
    "# Domain parameters\n",
    "SAMPLING_SECONDS = 30  # expected interval\n",
    "SESSION_MAX_GAP_FACTOR = 1.5  # gap > 45 s breaks a session\n",
    "SESSION_GAP_SECONDS = int(SAMPLING_SECONDS * SESSION_MAX_GAP_FACTOR)\n",
    "CURRENT_THRESHOLDS = {\n",
    "    'off_max': 0.2,\n",
    "    'standby_max': 1.8,\n",
    "    'spin_max': 5.0\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    'raw_file': str(RAW_FILE),\n",
    "    'sampling_seconds': SAMPLING_SECONDS,\n",
    "    'session_gap_seconds': SESSION_GAP_SECONDS,\n",
    "    'current_thresholds': CURRENT_THRESHOLDS,\n",
    "    'export_csv': 'drilling_sessions_enriched.csv'\n",
    "}\n",
    "\n",
    "print('Configuration:')\n",
    "for k,v in CONFIG.items():\n",
    "    print(f'  {k}: {v}')\n",
    "print(f'RAW_FILE exists: {RAW_FILE.exists()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9a8c4d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full load shape: (3900, 8)\n",
      "Memory usage (raw dtypes): 0.89 MB\n",
      "Iterated through 3900 rows using chunk size=50,000.\n",
      "First rows from first chunk:\n",
      "              timestamp device_id  seq  current_amp    gps_lat    gps_lon  \\\n",
      "0  2025-07-01T09:20:15Z  b4e1d9c2  410         7.30  52.393297  13.265675   \n",
      "1  2025-07-01T09:20:45Z  b4e1d9c2  411         5.79  52.393608  13.265867   \n",
      "\n",
      "   battery_level             ble_id  \n",
      "0             67  F4:12:FA:6C:9D:21  \n",
      "1             67  F4:12:FA:6C:9D:21  \n"
     ]
    }
   ],
   "source": [
    "# Section 2: Ingest Raw CSV (Streaming & Full Load)\n",
    "# Full load\n",
    "df_full = pd.read_csv(str(RAW_FILE))\n",
    "print(f'Full load shape: {df_full.shape}')\n",
    "mem_mb = df_full.memory_usage(deep=True).sum() / 1e6\n",
    "print(f'Memory usage (raw dtypes): {mem_mb:,.2f} MB')\n",
    "\n",
    "# Streaming / chunked approach example\n",
    "chunk_rows = 0\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(RAW_FILE, chunksize=50_000):\n",
    "    chunk_rows += len(chunk)\n",
    "    chunks.append(chunk.head(2))  # keep tiny sample for demonstration\n",
    "print(f'Iterated through {chunk_rows} rows using chunk size=50,000.')\n",
    "print('First rows from first chunk:')\n",
    "print(chunks[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeabde4",
   "metadata": {},
   "source": [
    "### Ingestion \n",
    "Two read strategies:\n",
    "1. Full load for total shape & memory footprint (`df_full`).\n",
    "2. Chunked iteration (50k) pattern for scalability; only small samples retained.\n",
    "Outputs validate: rows, columns, approximate memory MB, and preview rows. Confirms schema expectations early and provides fallback if memory limits arise in bigger deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb668162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp        string[python]\n",
      "device_id              category\n",
      "seq                       int32\n",
      "current_amp             float32\n",
      "gps_lat                 float64\n",
      "gps_lon                 float64\n",
      "battery_level              Int8\n",
      "ble_id                 category\n",
      "dtype: object\n",
      "Rows: 3900\n",
      "Coercion issues: None\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Define Explicit Schema & Enforce Data Types\n",
    "schema_dtypes = {\n",
    "    'timestamp': 'string',  # parse later\n",
    "    'device_id': 'category',\n",
    "    'seq': 'int32',\n",
    "    'current_amp': 'float32',\n",
    "    'gps_lat': 'float64',\n",
    "    'gps_lon': 'float64',\n",
    "    'battery_level': 'Int8',  # allows NA\n",
    "    'ble_id': 'category'\n",
    "}\n",
    "\n",
    "# Re-read with schema (except timestamp)\n",
    "df = pd.read_csv(RAW_FILE, dtype=schema_dtypes)\n",
    "print(df.dtypes)\n",
    "print('Rows:', len(df))\n",
    "\n",
    "# Report any coercion issues (pandas coercion already handled; we could check for non-numeric in numeric columns)\n",
    "issues = {}\n",
    "for col, expected in schema_dtypes.items():\n",
    "    if pd.api.types.is_numeric_dtype(df[col]) and df[col].isna().any():\n",
    "        na_pct = df[col].isna().mean()*100\n",
    "        issues[col] = f'Contains {na_pct:.2f}% NA after dtype coercion'\n",
    "print('Coercion issues:', issues or 'None')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911b576",
   "metadata": {},
   "source": [
    "### Missing Value Audit & Imputation \n",
    "Profiles NA distribution to prioritize cleaning steps, then forward-fills `battery_level` per device to smooth sparse gaps. Adds boolean `ble_id_missing` to later assess tag detection reliability. Expected output: table of NA counts/percentages and reduced (or eliminated) battery_level NAs after forward fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cdc63a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "               na_count     na_pct\n",
      "ble_id             2573  65.974359\n",
      "timestamp             0   0.000000\n",
      "seq                   0   0.000000\n",
      "device_id             0   0.000000\n",
      "current_amp           0   0.000000\n",
      "gps_lat               0   0.000000\n",
      "gps_lon               0   0.000000\n",
      "battery_level         0   0.000000\n",
      "Issues summary (non-zero NA columns):\n",
      "        na_count     na_pct\n",
      "ble_id      2573  65.974359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1252025665.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['battery_level'] = df.groupby('device_id')['battery_level'].ffill().astype('Int8')\n"
     ]
    }
   ],
   "source": [
    "# Section 5: Handle Missing Values & Data Quality Audit\n",
    "na_counts = df.isna().sum()\n",
    "na_pct = (na_counts / len(df))*100\n",
    "quality = pd.DataFrame({'na_count': na_counts, 'na_pct': na_pct}).sort_values('na_pct', ascending=False)\n",
    "print('Missing values summary:')\n",
    "print(quality)\n",
    "\n",
    "# Impute battery_level forward per device\n",
    "df['battery_level'] = df.groupby('device_id')['battery_level'].ffill().astype('Int8')\n",
    "\n",
    "# Flag missing BLE IDs\n",
    "df['ble_id_missing'] = df['ble_id'].isna()\n",
    "issues_summary = quality[quality.na_pct > 0]\n",
    "print('Issues summary (non-zero NA columns):')\n",
    "print(issues_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe2213",
   "metadata": {},
   "source": [
    "### Remove Duplicates & Sequence Integrity – Explanation\n",
    "Eliminates fully duplicated rows to prevent double counting, then inspects the `seq` field per device to locate missing sequence ranges (data loss). Consecutive gaps are summarized as (start, end) tuples. Expected output: number of duplicates removed (often 0) and printed gaps only if any sequence numbers are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "279bf3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate rows.\n",
      "Sequence gaps:\n",
      "Series([], dtype: object)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\3832802450.py:26: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  seq_gaps = df.groupby('device_id', observed=True).apply(find_seq_gaps)\n"
     ]
    }
   ],
   "source": [
    "# Section 6: Remove Duplicates & Sequence Integrity Check\n",
    "pre_dupe = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(f'Removed {pre_dupe - len(df)} duplicate rows.')\n",
    "\n",
    "# Sequence monotonic check & gaps\n",
    "def find_seq_gaps(g):\n",
    "    seq = g['seq'].to_numpy()\n",
    "    gaps = []\n",
    "    if len(seq) > 1:\n",
    "        missing = np.setdiff1d(np.arange(seq.min(), seq.max()+1), seq)\n",
    "        if missing.size:\n",
    "            # group consecutive missing\n",
    "            start = missing[0]\n",
    "            prev = missing[0]\n",
    "            for x in missing[1:]:\n",
    "                if x == prev + 1:\n",
    "                    prev = x\n",
    "                else:\n",
    "                    gaps.append((start, prev))\n",
    "                    start = x\n",
    "                    prev = x\n",
    "            gaps.append((start, prev))\n",
    "    return gaps\n",
    "\n",
    "seq_gaps = df.groupby('device_id', observed=True).apply(find_seq_gaps)\n",
    "print('Sequence gaps:')\n",
    "print(seq_gaps[seq_gaps.apply(len) > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2906aeb",
   "metadata": {},
   "source": [
    "### Geospatial Cleaning – Explanation\n",
    "Validates latitude/longitude ranges, removes invalid rows, detects motionless bursts via rolling std (potential GPS freeze), and produces smoothed latitude/longitude variants with a centered rolling median. Output: count of invalid coordinate removals (if any) and number of constant-coordinate bursts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "836b254c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant coordinate burst count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\3903203272.py:9: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['lat_rolling_std'] = df.groupby('device_id')['gps_lat'].transform(lambda s: s.rolling(5, min_periods=3).std())\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\3903203272.py:10: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['lon_rolling_std'] = df.groupby('device_id')['gps_lon'].transform(lambda s: s.rolling(5, min_periods=3).std())\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\3903203272.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_smooth'] = df.groupby('device_id')[col].transform(lambda s: s.rolling(3, center=True, min_periods=1).median())\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\3903203272.py:16: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_smooth'] = df.groupby('device_id')[col].transform(lambda s: s.rolling(3, center=True, min_periods=1).median())\n"
     ]
    }
   ],
   "source": [
    "# Section 7: Geospatial Data Cleaning (Latitude/Longitude Validation)\n",
    "valid_mask = df['gps_lat'].between(-90, 90) & df['gps_lon'].between(-180, 180)\n",
    "invalid_rows = (~valid_mask).sum()\n",
    "if invalid_rows:\n",
    "    print(f'Removing {invalid_rows} invalid coordinate rows.')\n",
    "    df = df[valid_mask]\n",
    "\n",
    "# Detect zero variance bursts (5-point rolling std == 0)\n",
    "df['lat_rolling_std'] = df.groupby('device_id')['gps_lat'].transform(lambda s: s.rolling(5, min_periods=3).std())\n",
    "df['lon_rolling_std'] = df.groupby('device_id')['gps_lon'].transform(lambda s: s.rolling(5, min_periods=3).std())\n",
    "constant_coords = (df['lat_rolling_std'] == 0) & (df['lon_rolling_std'] == 0)\n",
    "print('Constant coordinate burst count:', constant_coords.sum())\n",
    "\n",
    "# Optional smoothing (rolling median) - non-destructive\n",
    "for col in ['gps_lat','gps_lon']:\n",
    "    df[f'{col}_smooth'] = df.groupby('device_id')[col].transform(lambda s: s.rolling(3, center=True, min_periods=1).median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b694d7f",
   "metadata": {},
   "source": [
    "### Feature Engineering (Distance, Speed, Bearing) – Explanation\n",
    "Computes per-sample movement metrics per device by shifting previous coordinates. Uses haversine for geodesic distance (meters) and bearing for heading. Derives `distance_m`, `bearing_deg`, `speed_mps` (clipped to 0–20 to suppress spikes), and cumulative distance. Output preview shows first few engineered rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7d4363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  device_id  seq  distance_m  speed_mps  bearing_deg\n",
      "0  b4e1d9c2  410    0.000000   0.000000          NaN\n",
      "1  b4e1d9c2  411   36.954323   1.231811    20.643180\n",
      "2  b4e1d9c2  412   81.003448   2.700115   139.265107\n",
      "3  b4e1d9c2  413   39.776043   1.325868   271.441930\n",
      "4  b4e1d9c2  414   89.053589   2.968453    24.631961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1347757655.py:22: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['time_diff_s'] = df.groupby('device_id')['timestamp_dt'].diff().dt.total_seconds().fillna(0).astype('float32')\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1347757655.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_prev'] = df.groupby('device_id')[col].shift(1)\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1347757655.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_prev'] = df.groupby('device_id')[col].shift(1)\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1347757655.py:39: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['bearing_deg'] = df['bearing_deg'].fillna(method='ffill')\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1347757655.py:42: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df['cumulative_distance_m'] = df.groupby('device_id')['distance_m'].cumsum().astype('float32')\n"
     ]
    }
   ],
   "source": [
    "# Section 8: Feature Engineering: Delta Time, Distance, Speed, Bearing\n",
    "R_EARTH = 6371000.0  # meters\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R_EARTH * c\n",
    "\n",
    "def bearing(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlon = lon2 - lon1\n",
    "    x = np.sin(dlon) * np.cos(lat2)\n",
    "    y = np.cos(lat1)*np.sin(lat2) - np.sin(lat1)*np.cos(lat2)*np.cos(dlon)\n",
    "    brng = np.degrees(np.arctan2(x, y))\n",
    "    return (brng + 360) % 360\n",
    "\n",
    "# Compute time difference in seconds per device\n",
    "df['timestamp_dt'] = pd.to_datetime(df['timestamp'])\n",
    "df['time_diff_s'] = df.groupby('device_id')['timestamp_dt'].diff().dt.total_seconds().fillna(0).astype('float32')\n",
    "\n",
    "# shift per device\n",
    "for col in ['gps_lat','gps_lon']:\n",
    "    df[f'{col}_prev'] = df.groupby('device_id')[col].shift(1)\n",
    "\n",
    "mask_move = df['gps_lat_prev'].notna()\n",
    "df.loc[mask_move, 'distance_m'] = haversine(\n",
    "    df.loc[mask_move, 'gps_lat_prev'], df.loc[mask_move, 'gps_lon_prev'],\n",
    "    df.loc[mask_move, 'gps_lat'], df.loc[mask_move, 'gps_lon']\n",
    ")\n",
    "df['distance_m'] = df['distance_m'].fillna(0).astype('float32')\n",
    "\n",
    "df.loc[mask_move, 'bearing_deg'] = bearing(\n",
    "    df.loc[mask_move, 'gps_lat_prev'], df.loc[mask_move, 'gps_lon_prev'],\n",
    "    df.loc[mask_move, 'gps_lat'], df.loc[mask_move, 'gps_lon']\n",
    ")\n",
    "df['bearing_deg'] = df['bearing_deg'].fillna(method='ffill')\n",
    "\n",
    "df['speed_mps'] = (df['distance_m'] / df['time_diff_s'].replace(0, np.nan)).clip(0, 20).fillna(0).astype('float32')\n",
    "df['cumulative_distance_m'] = df.groupby('device_id')['distance_m'].cumsum().astype('float32')\n",
    "print(df[['device_id','seq','distance_m','speed_mps','bearing_deg']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2d4176",
   "metadata": {},
   "source": [
    "### Operational Power / State Classification – Explanation\n",
    "Translates raw current into discrete operational states using configured thresholds (OFF, STANDBY, SPIN, DRILL) and computes a normalized `power_index`. Rolling means (window 5) smooth short-term noise. Output preview lists state assignments and smoothed metrics for early rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b9b5209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  device_id  seq  current_amp op_state  power_index\n",
      "0  b4e1d9c2  410         7.30    DRILL        0.730\n",
      "1  b4e1d9c2  411         5.79    DRILL        0.579\n",
      "2  b4e1d9c2  412         5.51    DRILL        0.551\n",
      "3  b4e1d9c2  413         2.03     SPIN        0.203\n",
      "4  b4e1d9c2  414         6.98    DRILL        0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1515819354.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_roll5'] = df.groupby('device_id')[col].transform(lambda s: s.rolling(5, min_periods=1).mean()).astype('float32')\n",
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\1515819354.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df[f'{col}_roll5'] = df.groupby('device_id')[col].transform(lambda s: s.rolling(5, min_periods=1).mean()).astype('float32')\n"
     ]
    }
   ],
   "source": [
    "# Section 9: Energy / Operational Power Proxies (Domain-Aware Minimal)\n",
    "# We approximate relative power states without voltage; focus on current-driven proxies.\n",
    "# Motor state distinguishes idle spin vs drilling load using current thresholds.\n",
    "\n",
    "thr = CONFIG['current_thresholds']\n",
    "\n",
    "def classify_state(i):\n",
    "    if pd.isna(i):\n",
    "        return 'UNKNOWN'\n",
    "    if i <= thr['off_max']:\n",
    "        return 'OFF'\n",
    "    if i <= thr['standby_max']:\n",
    "        return 'STANDBY'\n",
    "    if i <= thr['spin_max']:\n",
    "        return 'SPIN'\n",
    "    return 'DRILL'\n",
    "\n",
    "# Operational state classification\n",
    "df['op_state'] = df['current_amp'].apply(classify_state)\n",
    "\n",
    "# Simple relative power index scaled to current (normalizing by 10 A for readability)\n",
    "df['power_index'] = (df['current_amp'] / 10.0).clip(0).astype('float32')\n",
    "\n",
    "# Rolling smoothing for current & power\n",
    "for col in ['current_amp','power_index']:\n",
    "    df[f'{col}_roll5'] = df.groupby('device_id')[col].transform(lambda s: s.rolling(5, min_periods=1).mean()).astype('float32')\n",
    "\n",
    "# Session-level tag presence placeholder (filled later after session assignment)\n",
    "print(df[['device_id','seq','current_amp','op_state','power_index']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872b2598",
   "metadata": {},
   "source": [
    "### Session Segmentation & BLE Tagging – Explanation\n",
    "Segments telemetry into sessions per device when time gaps exceed the configured threshold or sequence jumps indicate packet loss. Aggregates BLE IDs to flag tagged sessions and capture a dominant tag. Produces a session summary (duration, rows, distance, activity ratio, tag status) and counts tagged vs untagged sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "901c7217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session summary (head):\n",
      "           device_id                 start                   end  rows  \\\n",
      "session_id                                                               \n",
      "b4e1d9c2_0  b4e1d9c2  2025-07-01T09:20:15Z  2025-07-01T09:30:15Z    21   \n",
      "9f8c2a7d_0  9f8c2a7d  2025-07-01T19:39:26Z  2025-07-01T19:59:26Z    41   \n",
      "9f8c2a7d_1  9f8c2a7d  2025-07-01T23:33:52Z  2025-07-01T23:43:52Z    21   \n",
      "9f8c2a7d_2  9f8c2a7d  2025-07-02T06:22:10Z  2025-07-02T06:32:10Z    21   \n",
      "b4e1d9c2_1  b4e1d9c2  2025-07-02T22:44:10Z  2025-07-02T23:04:10Z    41   \n",
      "\n",
      "              distance_m  tagged             ble_id  duration_s  duration_min  \n",
      "session_id                                                                     \n",
      "b4e1d9c2_0   1501.454712    True  F4:12:FA:6C:9D:21       600.0          10.0  \n",
      "9f8c2a7d_0   2571.208008   False               None      1200.0          20.0  \n",
      "9f8c2a7d_1  35371.179688   False               None       600.0          10.0  \n",
      "9f8c2a7d_2  28007.292969   False               None       600.0          10.0  \n",
      "b4e1d9c2_1  16228.981445    True  A4:C1:38:1F:2B:7C      1200.0          20.0  \n",
      "\n",
      "Tagged session counts:\n",
      "tagged\n",
      "False    58\n",
      "True     40\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peppe\\AppData\\Local\\Temp\\ipykernel_59256\\4130355117.py:15: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(assign_sessions)\n"
     ]
    }
   ],
   "source": [
    "# Section 10: Session Segmentation & BLE Tag Enrichment (no power_index usage)\n",
    "\n",
    "def assign_sessions(g):\n",
    "    gap = g['time_diff_s'] > CONFIG['session_gap_seconds']\n",
    "    return gap.cumsum()\n",
    "\n",
    "df = df.sort_values(['device_id','timestamp'])\n",
    "\n",
    "for col in ['session_local_id', 'session_id', 'session_tagged', 'session_ble_id']:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "\n",
    "df['session_local_id'] = (\n",
    "    df.groupby('device_id', observed=True)\n",
    "      .apply(assign_sessions)\n",
    "      .reset_index(level=0, drop=True)\n",
    ")\n",
    "df['session_id'] = df['device_id'].astype(str) + '_' + df['session_local_id'].astype(str)\n",
    "\n",
    "def clean_ble_tags(series):\n",
    "    valid = series.dropna()\n",
    "    valid = valid[valid.astype(str).str.strip() != '']\n",
    "    valid = valid[valid.astype(str) != 'nan']\n",
    "    return valid.unique() if len(valid) > 0 else []\n",
    "\n",
    "session_ble = df.groupby('session_id', observed=True)['ble_id'].apply(clean_ble_tags)\n",
    "session_tagged = session_ble.apply(lambda arr: len(arr) > 0)\n",
    "session_ble_id = session_ble.apply(lambda arr: arr[0] if len(arr) > 0 else None)\n",
    "\n",
    "session_meta = pd.DataFrame({\n",
    "    'session_id': session_tagged.index,\n",
    "    'session_tagged': session_tagged.values,\n",
    "    'session_ble_id': session_ble_id.values\n",
    "})\n",
    "df = df.merge(session_meta, on='session_id', how='left')\n",
    "\n",
    "session_summary = (\n",
    "    df.groupby('session_id', observed=True).agg(\n",
    "        device_id=('device_id','first'),\n",
    "        start=('timestamp','min'),\n",
    "        end=('timestamp','max'),\n",
    "        rows=('seq','count'),\n",
    "        distance_m=('distance_m','sum'),\n",
    "        tagged=('session_tagged','first'),\n",
    "        ble_id=('session_ble_id','first')\n",
    "    )\n",
    "    .sort_values('start')\n",
    ")\n",
    "\n",
    "# Calculate duration as end time minus start time\n",
    "session_summary['start_dt'] = pd.to_datetime(session_summary['start'])\n",
    "session_summary['end_dt'] = pd.to_datetime(session_summary['end'])\n",
    "session_summary['duration_s'] = (session_summary['end_dt'] - session_summary['start_dt']).dt.total_seconds().astype('float32')\n",
    "\n",
    "# Drop temporary datetime columns\n",
    "session_summary = session_summary.drop(columns=['start_dt', 'end_dt'])\n",
    "\n",
    "# Add duration in minutes\n",
    "session_summary['duration_min'] = (session_summary['duration_s'] / 60.0).astype('float32')\n",
    "\n",
    "print('Session summary (head):')\n",
    "print(session_summary.head())\n",
    "\n",
    "print('\\nTagged session counts:')\n",
    "print(session_summary[\"tagged\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e64cc3",
   "metadata": {},
   "source": [
    "### Export – Explanation\n",
    "Writes a lean CSV containing only essential enriched columns (original telemetry + engineered movement metrics + state + session & BLE tagging). Column list is filtered to existing columns for robustness. Output: confirmation path and column count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "77947255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal CSV export written to: C:\\Users\\peppe\\Documents\\GitHub\\Telemetry-Analytics-Dashboard-for-Smart-Drilling-Machines\\public\\data\\drilling_sessions_enriched.csv (columns: 17)\n"
     ]
    }
   ],
   "source": [
    "# Section 14: Export (Minimal)\n",
    "# Lightweight CSV export of enriched dataframe with session & state features.\n",
    "\n",
    "minimal_export_path = PROCESSED_DIR / CONFIG['export_csv']\n",
    "export_cols = [\n",
    "    'timestamp','device_id','seq','current_amp','gps_lat','gps_lon','battery_level','ble_id',\n",
    "    'distance_m','speed_mps','bearing_deg','cumulative_distance_m','op_state','power_index',\n",
    "    'session_id','session_tagged','session_ble_id'\n",
    "]\n",
    "# Only keep columns that exist (robustness if dataset schema changes)\n",
    "export_cols = [c for c in export_cols if c in df.columns]\n",
    "df[export_cols].to_csv(minimal_export_path, index=False)\n",
    "print(f'Minimal CSV export written to: {minimal_export_path} (columns: {len(export_cols)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "378632fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session summary exported to: C:\\Users\\peppe\\Documents\\GitHub\\Telemetry-Analytics-Dashboard-for-Smart-Drilling-Machines\\public\\data\\session_summary.csv (rows: 98)\n"
     ]
    }
   ],
   "source": [
    "# Export session_summary with duration to CSV\n",
    "session_export_path = PROCESSED_DIR / 'session_summary.csv'\n",
    "session_summary.to_csv(session_export_path, index=True)\n",
    "print(f'Session summary exported to: {session_export_path} (rows: {len(session_summary)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301eb5c",
   "metadata": {},
   "source": [
    "### Integrity Checks – Explanation\n",
    "Runs domain sanity validations: sampling gap plausibility (no extreme gaps), geographic bounds, non-negative distance/speed, and consistent tagging within each session. Any violation raises an assertion to fail fast. Output: confirmation message if all pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cdaaf5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running integrity checks...\n",
      "Warning: detected 95 extreme positive gaps (> 135s) and 0 negative gaps. Flags added as columns gap_flag_extreme / gap_flag_negative.\n",
      "Session tagging consistency check passed.\n",
      "Integrity checks completed.\n"
     ]
    }
   ],
   "source": [
    "# Section 15: Integrity Checks (Domain-Aware Minimal)\n",
    "print('Running integrity checks...')\n",
    "\n",
    "# 1. Sampling interval plausibility (soft checks instead of hard assert to avoid notebook stop)\n",
    "extreme_gap_threshold = CONFIG['session_gap_seconds'] * 3\n",
    "extreme_gaps = df['time_diff_s'] > extreme_gap_threshold\n",
    "negative_gaps = df['time_diff_s'] < 0\n",
    "\n",
    "if extreme_gaps.any() or negative_gaps.any():\n",
    "\tprint(\n",
    "\t\tf'Warning: detected {extreme_gaps.sum()} extreme positive gaps (> {extreme_gap_threshold}s) '\n",
    "\t\tf'and {negative_gaps.sum()} negative gaps. Flags added as columns gap_flag_extreme / gap_flag_negative.'\n",
    "\t)\n",
    "\t# Add (or update) flag columns\n",
    "\tdf['gap_flag_extreme'] = extreme_gaps\n",
    "\tdf['gap_flag_negative'] = negative_gaps\n",
    "else:\n",
    "\tprint('Sampling interval within expected bounds.')\n",
    "\n",
    "# 2. Coordinates sanity\n",
    "assert df['gps_lat'].between(-90,90).all() and df['gps_lon'].between(-180,180).all(), 'Invalid coordinates present.'\n",
    "\n",
    "# 3. Non-negative distances & speeds\n",
    "assert (df['distance_m'] >= 0).all(), 'Negative distances found.'\n",
    "assert (df['speed_mps'] >= 0).all(), 'Negative speeds found.'\n",
    "\n",
    "# 4. Session tagging consistency (robust to cells executed out-of-order)\n",
    "if {'session_id', 'session_tagged'}.issubset(df.columns):\n",
    "\tsession_tag_consistency = df.groupby('session_id')['session_tagged'].nunique().le(1).all()\n",
    "\tif not session_tag_consistency:\n",
    "\t\traise AssertionError('Inconsistent tagging flag within a session.')\n",
    "\telse:\n",
    "\t\tprint('Session tagging consistency check passed.')\n",
    "else:\n",
    "\tprint('Skipping session tagging consistency check (session_id/session_tagged not present – run segmentation cell).')\n",
    "\n",
    "print('Integrity checks completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e9308e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: C:\\Users\\peppe\\Documents\\GitHub\\Telemetry-Analytics-Dashboard-for-Smart-Drilling-Machines\\public\\data\\drilling_sessions_enriched.csv (exists: True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>device_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>current_amp</th>\n",
       "      <th>gps_lat</th>\n",
       "      <th>gps_lon</th>\n",
       "      <th>battery_level</th>\n",
       "      <th>ble_id</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>speed_mps</th>\n",
       "      <th>bearing_deg</th>\n",
       "      <th>cumulative_distance_m</th>\n",
       "      <th>op_state</th>\n",
       "      <th>power_index</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_tagged</th>\n",
       "      <th>session_ble_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-05T04:40:35Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>453</td>\n",
       "      <td>3.38</td>\n",
       "      <td>52.544487</td>\n",
       "      <td>13.168079</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.096659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>SPIN</td>\n",
       "      <td>0.338</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-05T04:41:05Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>454</td>\n",
       "      <td>6.03</td>\n",
       "      <td>52.545018</td>\n",
       "      <td>13.168150</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>59.239388</td>\n",
       "      <td>1.974646</td>\n",
       "      <td>4.648727</td>\n",
       "      <td>59.239388</td>\n",
       "      <td>DRILL</td>\n",
       "      <td>0.603</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-05T04:41:35Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>455</td>\n",
       "      <td>1.93</td>\n",
       "      <td>52.544613</td>\n",
       "      <td>13.167192</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>78.897194</td>\n",
       "      <td>2.629906</td>\n",
       "      <td>235.194857</td>\n",
       "      <td>138.136580</td>\n",
       "      <td>SPIN</td>\n",
       "      <td>0.193</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-05T04:42:05Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>456</td>\n",
       "      <td>8.11</td>\n",
       "      <td>52.544925</td>\n",
       "      <td>13.167072</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>35.629192</td>\n",
       "      <td>1.187640</td>\n",
       "      <td>346.835210</td>\n",
       "      <td>173.765780</td>\n",
       "      <td>DRILL</td>\n",
       "      <td>0.811</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-05T04:42:35Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>457</td>\n",
       "      <td>6.62</td>\n",
       "      <td>52.544484</td>\n",
       "      <td>13.167165</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.438583</td>\n",
       "      <td>1.647953</td>\n",
       "      <td>172.691805</td>\n",
       "      <td>223.204360</td>\n",
       "      <td>DRILL</td>\n",
       "      <td>0.662</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-07-05T04:43:05Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>458</td>\n",
       "      <td>6.50</td>\n",
       "      <td>52.544853</td>\n",
       "      <td>13.168088</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>74.694220</td>\n",
       "      <td>2.489807</td>\n",
       "      <td>56.679354</td>\n",
       "      <td>297.898560</td>\n",
       "      <td>DRILL</td>\n",
       "      <td>0.650</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-07-05T04:43:35Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>459</td>\n",
       "      <td>5.10</td>\n",
       "      <td>52.544829</td>\n",
       "      <td>13.167507</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>39.378983</td>\n",
       "      <td>1.312633</td>\n",
       "      <td>266.114369</td>\n",
       "      <td>337.277560</td>\n",
       "      <td>DRILL</td>\n",
       "      <td>0.510</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-07-05T04:44:05Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>460</td>\n",
       "      <td>4.09</td>\n",
       "      <td>52.544715</td>\n",
       "      <td>13.167623</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.906969</td>\n",
       "      <td>0.496899</td>\n",
       "      <td>148.250299</td>\n",
       "      <td>352.184540</td>\n",
       "      <td>SPIN</td>\n",
       "      <td>0.409</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-07-05T04:44:35Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>461</td>\n",
       "      <td>2.17</td>\n",
       "      <td>52.544052</td>\n",
       "      <td>13.167412</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>75.090320</td>\n",
       "      <td>2.503010</td>\n",
       "      <td>190.953844</td>\n",
       "      <td>427.274840</td>\n",
       "      <td>SPIN</td>\n",
       "      <td>0.217</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-07-05T04:45:05Z</td>\n",
       "      <td>7a3f55e1</td>\n",
       "      <td>462</td>\n",
       "      <td>2.79</td>\n",
       "      <td>52.544368</td>\n",
       "      <td>13.167751</td>\n",
       "      <td>77</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "      <td>41.954390</td>\n",
       "      <td>1.398480</td>\n",
       "      <td>33.120821</td>\n",
       "      <td>469.229250</td>\n",
       "      <td>SPIN</td>\n",
       "      <td>0.279</td>\n",
       "      <td>7a3f55e1_0</td>\n",
       "      <td>True</td>\n",
       "      <td>A4:C1:38:1F:2B:7C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp device_id  seq  current_amp    gps_lat    gps_lon  \\\n",
       "0  2025-07-05T04:40:35Z  7a3f55e1  453         3.38  52.544487  13.168079   \n",
       "1  2025-07-05T04:41:05Z  7a3f55e1  454         6.03  52.545018  13.168150   \n",
       "2  2025-07-05T04:41:35Z  7a3f55e1  455         1.93  52.544613  13.167192   \n",
       "3  2025-07-05T04:42:05Z  7a3f55e1  456         8.11  52.544925  13.167072   \n",
       "4  2025-07-05T04:42:35Z  7a3f55e1  457         6.62  52.544484  13.167165   \n",
       "5  2025-07-05T04:43:05Z  7a3f55e1  458         6.50  52.544853  13.168088   \n",
       "6  2025-07-05T04:43:35Z  7a3f55e1  459         5.10  52.544829  13.167507   \n",
       "7  2025-07-05T04:44:05Z  7a3f55e1  460         4.09  52.544715  13.167623   \n",
       "8  2025-07-05T04:44:35Z  7a3f55e1  461         2.17  52.544052  13.167412   \n",
       "9  2025-07-05T04:45:05Z  7a3f55e1  462         2.79  52.544368  13.167751   \n",
       "\n",
       "   battery_level             ble_id  distance_m  speed_mps  bearing_deg  \\\n",
       "0             77  A4:C1:38:1F:2B:7C    0.000000   0.000000     8.096659   \n",
       "1             77  A4:C1:38:1F:2B:7C   59.239388   1.974646     4.648727   \n",
       "2             77  A4:C1:38:1F:2B:7C   78.897194   2.629906   235.194857   \n",
       "3             77  A4:C1:38:1F:2B:7C   35.629192   1.187640   346.835210   \n",
       "4             77                NaN   49.438583   1.647953   172.691805   \n",
       "5             77  A4:C1:38:1F:2B:7C   74.694220   2.489807    56.679354   \n",
       "6             77  A4:C1:38:1F:2B:7C   39.378983   1.312633   266.114369   \n",
       "7             77                NaN   14.906969   0.496899   148.250299   \n",
       "8             77  A4:C1:38:1F:2B:7C   75.090320   2.503010   190.953844   \n",
       "9             77  A4:C1:38:1F:2B:7C   41.954390   1.398480    33.120821   \n",
       "\n",
       "   cumulative_distance_m op_state  power_index  session_id  session_tagged  \\\n",
       "0               0.000000     SPIN        0.338  7a3f55e1_0            True   \n",
       "1              59.239388    DRILL        0.603  7a3f55e1_0            True   \n",
       "2             138.136580     SPIN        0.193  7a3f55e1_0            True   \n",
       "3             173.765780    DRILL        0.811  7a3f55e1_0            True   \n",
       "4             223.204360    DRILL        0.662  7a3f55e1_0            True   \n",
       "5             297.898560    DRILL        0.650  7a3f55e1_0            True   \n",
       "6             337.277560    DRILL        0.510  7a3f55e1_0            True   \n",
       "7             352.184540     SPIN        0.409  7a3f55e1_0            True   \n",
       "8             427.274840     SPIN        0.217  7a3f55e1_0            True   \n",
       "9             469.229250     SPIN        0.279  7a3f55e1_0            True   \n",
       "\n",
       "      session_ble_id  \n",
       "0  A4:C1:38:1F:2B:7C  \n",
       "1  A4:C1:38:1F:2B:7C  \n",
       "2  A4:C1:38:1F:2B:7C  \n",
       "3  A4:C1:38:1F:2B:7C  \n",
       "4  A4:C1:38:1F:2B:7C  \n",
       "5  A4:C1:38:1F:2B:7C  \n",
       "6  A4:C1:38:1F:2B:7C  \n",
       "7  A4:C1:38:1F:2B:7C  \n",
       "8  A4:C1:38:1F:2B:7C  \n",
       "9  A4:C1:38:1F:2B:7C  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview public/data/drilling_sessions_enriched.csv — first 10 rows (simple)\n",
    "csv_path = PROCESSED_DIR / CONFIG['export_csv']\n",
    "print(f'Reading: {csv_path} (exists: {csv_path.exists()})')\n",
    "df_preview = pd.read_csv(csv_path)\n",
    "df_preview.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drilling-telemetry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
